"""Reward functions for GRPO training.

4-component reward:
1. r_qa: F1 score of predicted answer vs gold answer
2. r_tool: Validity of generated tool calls
3. r_compress: Memory compression efficiency
4. r_valid: Content placement correctness
"""

from __future__ import annotations

import re
from collections import Counter
from typing import Any

from memory.operations import MemoryOperation, validate_operations


def compute_reward(
    predicted_answer: str,
    gold_answer: str,
    operations: list[MemoryOperation],
    graph_stats: dict[str, Any],
    max_tokens: int = 2048,
    weights: dict[str, float] | None = None,
) -> float:
    """Compute composite reward for GRPO training.

    Args:
        predicted_answer: Answer generated by Answer Agent.
        gold_answer: Ground truth answer from dataset.
        operations: Memory operations generated by Memory Manager.
        graph_stats: Current graph statistics (total_nodes, etc.).
        max_tokens: Maximum allowed memory tokens.
        weights: Custom weights for each component.

    Returns:
        Float reward value.
    """
    w = weights or {
        "qa": 1.0,
        "tool": 0.05,
        "compress": 0.05,
        "valid": 0.1,
    }

    r_qa = f1_score(predicted_answer, gold_answer)
    r_tool = validate_operations(operations) if operations else 0.0
    r_compress = compression_reward(graph_stats, max_tokens)
    r_valid = content_placement_score(operations)

    total = (
        w["qa"] * r_qa
        + w["tool"] * r_tool
        + w["compress"] * r_compress
        + w["valid"] * r_valid
    )

    return total


def f1_score(prediction: str, reference: str) -> float:
    """Token-level F1 score between prediction and reference."""
    pred_tokens = _normalize_and_tokenize(prediction)
    ref_tokens = _normalize_and_tokenize(reference)

    if not pred_tokens or not ref_tokens:
        return 1.0 if pred_tokens == ref_tokens else 0.0

    pred_counter = Counter(pred_tokens)
    ref_counter = Counter(ref_tokens)

    common = sum((pred_counter & ref_counter).values())

    if common == 0:
        return 0.0

    precision = common / len(pred_tokens)
    recall = common / len(ref_tokens)

    return 2 * precision * recall / (precision + recall)


def exact_match(prediction: str, reference: str) -> float:
    """Normalized exact match score."""
    return 1.0 if _normalize(prediction) == _normalize(reference) else 0.0


def compression_reward(
    graph_stats: dict[str, Any],
    max_tokens: int = 2048,
) -> float:
    """Reward for keeping memory compact.

    Higher reward for using fewer tokens.
    """
    total_nodes = graph_stats.get("total_nodes", 0)
    # Rough estimate: each node ~ 50 tokens
    estimated_tokens = total_nodes * 50

    if max_tokens <= 0:
        return 1.0

    ratio = estimated_tokens / max_tokens
    return max(0.0, 1.0 - ratio)


def content_placement_score(operations: list[MemoryOperation]) -> float:
    """Score how well content is placed in the right memory type.

    Heuristic checks:
    - Personal preferences → core
    - Facts, knowledge → semantic
    - Events, timestamps → episodic
    """
    if not operations:
        return 0.0

    correct = 0
    total = 0

    for op in operations:
        if op.action not in ("add", "update"):
            continue
        total += 1
        content_lower = op.content.lower()

        if op.memory_type == "core":
            # Core should contain preferences, profile
            if any(w in content_lower for w in [
                "prefer", "like", "name", "age", "favorite",
                "profile", "personality", "occupation",
            ]):
                correct += 1
        elif op.memory_type == "semantic":
            # Semantic should contain facts
            if any(w in content_lower for w in [
                "is", "are", "was", "has", "means", "works",
                "lives", "located", "capital", "born",
            ]):
                correct += 1
        elif op.memory_type == "episodic":
            # Episodic should contain events
            if any(w in content_lower for w in [
                "went", "visited", "happened", "met", "said",
                "yesterday", "today", "last week", "event",
            ]):
                correct += 1

    return correct / total if total > 0 else 1.0


def _normalize(text: str) -> str:
    """Normalize text for comparison."""
    text = text.lower().strip()
    text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r"\s+", " ", text)
    return text


def _normalize_and_tokenize(text: str) -> list[str]:
    """Normalize and tokenize text."""
    return _normalize(text).split()
